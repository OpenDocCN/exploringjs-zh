["```js\nReadableStream -pipeTo-> TransformStream -pipeTo-> WriteableStream\n```", "```js\nconst response = await fetch('https://example.com');\nconst readableStream = response.body;\n```", "```js\ninterface ReadableStream<TChunk> {\n getReader(): ReadableStreamDefaultReader<TChunk>;\n readonly locked: boolean;\n [Symbol.asyncIterator](): AsyncIterator<TChunk>;\n\n cancel(reason?: any): Promise<void>;\n\n pipeTo(\n destination: WritableStream<TChunk>,\n options?: StreamPipeOptions\n ): Promise<void>;\n pipeThrough<TChunk2>(\n transform: ReadableWritablePair<TChunk2, TChunk>,\n options?: StreamPipeOptions\n ): ReadableStream<TChunk2>;\n\n // Not used in this chapter:\n tee(): [ReadableStream<TChunk>, ReadableStream<TChunk>];\n}\n\ninterface StreamPipeOptions {\n signal?: AbortSignal;\n preventClose?: boolean;\n preventAbort?: boolean;\n preventCancel?: boolean;\n}\n```", "```js\ninterface ReadableStreamGenericReader {\n readonly closed: Promise<undefined>;\n cancel(reason?: any): Promise<void>;\n}\ninterface ReadableStreamDefaultReader<TChunk>\n extends ReadableStreamGenericReader\n{\n releaseLock(): void;\n read(): Promise<ReadableStreamReadResult<TChunk>>;\n}\n\ninterface ReadableStreamReadResult<TChunk> {\n done: boolean;\n value: TChunk | undefined;\n}\n```", "```js\nconst reader = readableStream.getReader(); // (A)\nassert.equal(readableStream.locked, true); // (B)\ntry {\n while (true) {\n const {done, value: chunk} = await reader.read(); // (C)\n if (done) break;\n // Use `chunk`\n }\n} finally {\n reader.releaseLock(); // (D)\n}\n```", "```js\nimport * as fs from 'node:fs';\nimport {Readable} from 'node:stream';\n\nconst nodeReadable = fs.createReadStream(\n 'data.txt', {encoding: 'utf-8'});\nconst webReadableStream = Readable.toWeb(nodeReadable); // (A)\n\nconst reader = webReadableStream.getReader();\ntry {\n while (true) {\n const {done, value} = await reader.read();\n if (done) break;\n console.log(value);\n }\n} finally {\n reader.releaseLock();\n}\n// Output:\n// 'Content of text file\\n'\n```", "```js\n/**\n * Returns a string with the contents of `readableStream`.\n */\nasync function readableStreamToString(readableStream) {\n const reader = readableStream.getReader();\n try {\n let result = '';\n while (true) {\n const {done, value} = await reader.read();\n if (done) {\n return result; // (A)\n }\n result += value;\n }\n } finally {\n reader.releaseLock(); // (B)\n }\n}\n```", "```js\nconst iterator = readableStream[Symbol.asyncIterator]();\nlet exhaustive = false;\ntry {\n while (true) {\n let chunk;\n ({done: exhaustive, value: chunk} = await iterator.next());\n if (exhaustive) break;\n console.log(chunk);\n }\n} finally {\n // If the loop was terminated before we could iterate exhaustively\n // (via an exception or `return`), we must call `iterator.return()`.\n // Check if that was the case.\n if (!exhaustive) {\n iterator.return();\n }\n}\n```", "```js\nfor await (const chunk of readableStream) {\n console.log(chunk);\n}\n```", "```js\nimport * as fs from 'node:fs';\nimport {Readable} from 'node:stream';\n\nconst nodeReadable = fs.createReadStream(\n 'text-file.txt', {encoding: 'utf-8'});\nconst webReadableStream = Readable.toWeb(nodeReadable);\nfor await (const chunk of webReadableStream) {\n console.log(chunk);\n}\n// Output:\n// 'Content of text file'\n```", "```js\n/**\n * Returns a string with the contents of `readableStream`.\n */\nasync function readableStreamToString2(readableStream) {\n let result = '';\n for await (const chunk of readableStream) {\n result += chunk;\n }\n return result;\n}\n```", "```js\nasync function* getAsyncIterableFor(readableStream) {\n const reader = readableStream.getReader();\n try {\n while (true) {\n const {done, value} = await reader.read();\n if (done) return;\n yield value;\n }\n } finally {\n reader.releaseLock();\n }\n}\n```", "```js\nnew ReadableStream(underlyingSource?, queuingStrategy?)\n```", "```js\ninterface UnderlyingSource<TChunk> {\n start?(\n controller: ReadableStreamController<TChunk>\n ): void | Promise<void>;\n pull?(\n controller: ReadableStreamController<TChunk>\n ): void | Promise<void>;\n cancel?(reason?: any): void | Promise<void>;\n\n // Only used in byte streams and ignored in this section:\n type: 'bytes' | undefined;\n autoAllocateChunkSize: bigint;\n}\n```", "```js\ntype ReadableStreamController<TChunk> =\n | ReadableStreamDefaultController<TChunk>\n | ReadableByteStreamController<TChunk> // ignored here\n;\n\ninterface ReadableStreamDefaultController<TChunk> {\n enqueue(chunk?: TChunk): void;\n readonly desiredSize: number | null;\n close(): void;\n error(err?: any): void;\n}\n```", "```js\nconst readableStream = new ReadableStream({\n start(controller) {\n controller.enqueue('First line\\n'); // (A)\n controller.enqueue('Second line\\n'); // (B)\n controller.close(); // (C)\n },\n});\nfor await (const chunk of readableStream) {\n console.log(chunk);\n}\n\n// Output:\n// 'First line\\n'\n// 'Second line\\n'\n```", "```js\nfunction makeReadableBackpressureSocketStream(host, port) {\n const socket = createBackpressureSocket(host, port);\n\n return new ReadableStream({\n start(controller) {\n socket.ondata = event => {\n controller.enqueue(event.data);\n\n if (controller.desiredSize <= 0) {\n // The internal queue is full, so propagate\n // the backpressure signal to the underlying source.\n socket.readStop();\n }\n };\n\n socket.onend = () => controller.close();\n socket.onerror = () => controller.error(\n new Error('The socket errored!'));\n },\n\n pull() {\n // This is called if the internal queue has been emptied, but the\n // stream\u2019s consumer still wants more data. In that case, restart\n // the flow of data if we have previously paused it.\n socket.readStart();\n },\n\n cancel() {\n socket.close();\n },\n });\n}\n```", "```js\n/**\n * @param  iterable an iterable (asynchronous or synchronous)\n */\n function iterableToReadableStream(iterable) {\n return new ReadableStream({\n start() {\n if (typeof iterable[Symbol.asyncIterator] === 'function') {\n this.iterator = iterable[Symbol.asyncIterator]();\n } else if (typeof iterable[Symbol.iterator] === 'function') {\n this.iterator = iterable[Symbol.iterator]();\n } else {\n throw new Error('Not an iterable: ' + iterable);\n }\n },\n\n async pull(controller) {\n if (this.iterator === null) return;\n // Sync iterators return non-Promise values,\n // but `await` doesn\u2019t mind and simply passes them on\n const {value, done} = await this.iterator.next();\n if (done) {\n this.iterator = null;\n controller.close();\n return;\n }\n controller.enqueue(value);\n },\n\n cancel() {\n this.iterator = null;\n controller.close();\n },\n });\n}\n```", "```js\nasync function* genAsyncIterable() {\n yield 'how';\n yield 'are';\n yield 'you';\n}\nconst readableStream = iterableToReadableStream(genAsyncIterable());\nfor await (const chunk of readableStream) {\n console.log(chunk);\n}\n\n// Output:\n// 'how'\n// 'are'\n// 'you'\n```", "```js\nconst syncIterable = ['hello', 'everyone'];\nconst readableStream = iterableToReadableStream(syncIterable);\nfor await (const chunk of readableStream) {\n console.log(chunk);\n}\n\n// Output:\n// 'hello'\n// 'everyone'\n```", "```js\ninterface WritableStream<TChunk> {\n getWriter(): WritableStreamDefaultWriter<TChunk>;\n readonly locked: boolean;\n\n close(): Promise<void>;\n abort(reason?: any): Promise<void>;\n}\n```", "```js\ninterface WritableStreamDefaultWriter<TChunk> {\n readonly desiredSize: number | null;\n readonly ready: Promise<undefined>;\n write(chunk?: TChunk): Promise<void>;\n releaseLock(): void;\n\n close(): Promise<void>;\n readonly closed: Promise<undefined>;\n abort(reason?: any): Promise<void>;\n}\n```", "```js\nconst writer = writableStream.getWriter(); // (A)\nassert.equal(writableStream.locked, true); // (B)\ntry {\n // Writing the chunks (explained later)\n} finally {\n writer.releaseLock(); // (C)\n}\n```", "```js\nawait writer.write('Chunk 1');\nawait writer.write('Chunk 2');\nawait writer.close();\n```", "```js\nwriter.write('Chunk 1').catch(() => {}); // (A)\nwriter.write('Chunk 2').catch(() => {}); // (B)\nawait writer.close(); // reports errors\n```", "```js\nignoreRejections(\n writer.write('Chunk 1'),\n writer.write('Chunk 2'),\n);\nawait writer.close(); // reports errors\n\nfunction ignoreRejections(...promises) {\n for (const promise of promises) {\n promise.catch(() => {});\n }\n}\n```", "```js\nawait writer.ready; // reports errors\n// How much room do we have?\nconsole.log(writer.desiredSize);\nwriter.write('Chunk 1').catch(() => {});\n\nawait writer.ready; // reports errors\n// How much room do we have?\nconsole.log(writer.desiredSize);\nwriter.write('Chunk 2').catch(() => {});\n\nawait writer.close(); // reports errors\n```", "```js\nimport * as fs from 'node:fs';\nimport {Writable} from 'node:stream';\n\nconst nodeWritable = fs.createWriteStream(\n 'new-file.txt', {encoding: 'utf-8'}); // (A)\nconst webWritableStream = Writable.toWeb(nodeWritable); // (B)\n\nconst writer = webWritableStream.getWriter();\ntry {\n await writer.write('First line\\n');\n await writer.write('Second line\\n');\n await writer.close();\n} finally {\n writer.releaseLock()\n}\n```", "```js\nawait readableStream.pipeTo(writableStream);\n```", "```js\nconst readableStream = new ReadableStream({ // (A)\n start(controller) {\n controller.enqueue('First line\\n');\n controller.enqueue('Second line\\n');\n controller.close();\n },\n});\nconst writableStream = new WritableStream({ // (B)\n write(chunk) {\n console.log('WRITE: ' + JSON.stringify(chunk));\n },\n close() {\n console.log('CLOSE WritableStream');\n },\n});\n\nconsole.log('Before .pipeTo()');\nconst promise = readableStream.pipeTo(writableStream); // (C)\npromise.then(() => console.log('Promise fulfilled'));\nconsole.log('After .pipeTo()');\n\n// Output:\n// 'Before .pipeTo()'\n// 'After .pipeTo()'\n// 'WRITE: \"First line\\n\"'\n// 'WRITE: \"Second line\\n\"'\n// 'CLOSE WritableStream'\n// 'Promise fulfilled'\n```", "```js\nconst webReadableStream = new ReadableStream({ // (A)\n async start(controller) {\n controller.enqueue('First line\\n');\n controller.enqueue('Second line\\n');\n controller.close();\n },\n});\n\nconst nodeWritable = fs.createWriteStream( // (B)\n 'data.txt', {encoding: 'utf-8'});\nconst webWritableStream = Writable.toWeb(nodeWritable); // (C)\n\nawait webReadableStream.pipeTo(webWritableStream); // (D)\n```", "```js\nfunction createReadableStream(prefix) {\n return new ReadableStream({\n async start(controller) {\n controller.enqueue(prefix + 'chunk 1');\n controller.enqueue(prefix + 'chunk 2');\n controller.close();\n },\n });\n}\n\nconst writableStream = new WritableStream({\n write(chunk) {\n console.log('WRITE ' + JSON.stringify(chunk));\n },\n close() {\n console.log('CLOSE');\n },\n abort(err) {\n console.log('ABORT ' + err);\n },\n});\n\nawait createReadableStream('Stream 1: ')\n .pipeTo(writableStream, {preventClose: true}); // (A)\nawait createReadableStream('Stream 2: ')\n .pipeTo(writableStream, {preventClose: true}); // (B)\nawait writableStream.close();\n\n// Output\n// 'WRITE \"Stream 1: chunk 1\"'\n// 'WRITE \"Stream 1: chunk 2\"'\n// 'WRITE \"Stream 2: chunk 1\"'\n// 'WRITE \"Stream 2: chunk 2\"'\n// 'CLOSE'\n```", "```js\nnew WritableStream(underlyingSink?, queuingStrategy?)\n```", "```js\ninterface UnderlyingSink<TChunk> {\n start?(\n controller: WritableStreamDefaultController\n ): void | Promise<void>;\n write?(\n chunk: TChunk,\n controller: WritableStreamDefaultController\n ): void | Promise<void>;\n close?(): void | Promise<void>;;\n abort?(reason?: any): void | Promise<void>;\n}\n```", "```js\ninterface WritableStreamDefaultController {\n readonly signal: AbortSignal;\n error(err?: any): void;\n}\n```", "```js\nconst readableStream = new ReadableStream({\n start(controller) {\n controller.enqueue('First chunk');\n controller.enqueue('Second chunk');\n controller.close();\n },\n});\nawait readableStream.pipeTo(\n new WritableStream({\n write(chunk) {\n console.log('WRITE ' + JSON.stringify(chunk));\n },\n close() {\n console.log('CLOSE');\n },\n abort(err) {\n console.log('ABORT ' + err);\n },\n })\n);\n// Output:\n// 'WRITE \"First chunk\"'\n// 'WRITE \"Second chunk\"'\n// 'CLOSE'\n```", "```js\nclass StringWritableStream extends WritableStream {\n #string = '';\n constructor() {\n super({\n // We need to access the `this` of `StringWritableStream`.\n // Hence the arrow function (and not a method).\n write: (chunk) => {\n this.#string += chunk;\n },\n });\n }\n getString() {\n return this.#string;\n }\n}\nconst stringStream = new StringWritableStream();\nconst writer = stringStream.getWriter();\ntry {\n await writer.write('How are');\n await writer.write(' you?');\n await writer.close();\n} finally {\n writer.releaseLock()\n}\nassert.equal(\n stringStream.getString(),\n 'How are you?'\n);\n```", "```js\nfunction StringcreateWritableStream() {\n let string = '';\n return {\n stream: new WritableStream({\n write(chunk) {\n string += chunk;\n },\n }),\n getString() {\n return string;\n },\n };\n}\n\nconst stringStream = StringcreateWritableStream();\nconst writer = stringStream.stream.getWriter();\ntry {\n await writer.write('How are');\n await writer.write(' you?');\n await writer.close();\n} finally {\n writer.releaseLock()\n}\nassert.equal(\n stringStream.getString(),\n 'How are you?'\n);\n```", "```js\nconst transformedStream = readableStream.pipeThrough(transformStream);\n```", "```js\ninterface ReadableWritablePair<RChunk, WChunk> {\n readable: ReadableStream<RChunk>;\n writable: WritableStream<WChunk>;\n}\n```", "```js\nconst response = await fetch('https://example.com');\nconst readableByteStream = response.body;\nconst readableStream = readableByteStream\n .pipeThrough(new TextDecoderStream('utf-8'));\nfor await (const stringChunk of readableStream) {\n console.log(stringChunk);\n}\n```", "```js\n// echo-stdin.mjs\nimport {Readable} from 'node:stream';\n\nconst webStream = Readable.toWeb(process.stdin)\n .pipeThrough(new TextDecoderStream('utf-8'));\nfor await (const chunk of webStream) {\n console.log('>>>', chunk);\n}\n```", "```js\ninterface Transformer<TInChunk, TOutChunk> {\n start?(\n controller: TransformStreamDefaultController<TOutChunk>\n ): void | Promise<void>;\n transform?(\n chunk: TInChunk,\n controller: TransformStreamDefaultController<TOutChunk>\n ): void | Promise<void>;\n flush?(\n controller: TransformStreamDefaultController<TOutChunk>\n ): void | Promise<void>;\n}\n```", "```js\ninterface TransformStreamDefaultController<TOutChunk> {\n enqueue(chunk?: TOutChunk): void;\n readonly desiredSize: number | null;\n terminate(): void;\n error(err?: any): void;\n}\n```", "```js\nclass ChunksToLinesTransformer {\n #previous = '';\n\n transform(chunk, controller) {\n let startSearch = this.#previous.length;\n this.#previous += chunk;\n while (true) {\n // Works for EOL === '\\n' and EOL === '\\r\\n'\n const eolIndex = this.#previous.indexOf('\\n', startSearch);\n if (eolIndex < 0) break;\n // Line includes the EOL\n const line = this.#previous.slice(0, eolIndex+1);\n controller.enqueue(line);\n this.#previous = this.#previous.slice(eolIndex+1);\n startSearch = 0;\n }\n }\n\n flush(controller) {\n // Clean up and enqueue any text we\u2019re still holding on to\n if (this.#previous.length > 0) {\n controller.enqueue(this.#previous);\n }\n }\n}\nclass ChunksToLinesStream extends TransformStream {\n constructor() {\n super(new ChunksToLinesTransformer());\n }\n}\n\nconst stream = new ReadableStream({\n async start(controller) {\n controller.enqueue('multiple\\nlines of\\ntext');\n controller.close();\n },\n});\nconst transformStream = new ChunksToLinesStream();\nconst transformed = stream.pipeThrough(transformStream);\n\nfor await (const line of transformed) {\n console.log('>>>', JSON.stringify(line));\n}\n\n// Output:\n// '>>> \"multiple\\n\"'\n// '>>> \"lines of\\n\"'\n// '>>> \"text\"'\n```", "```js\nconst stream = new ReadableStream({\n async start(controller) {\n controller.enqueue('one');\n controller.enqueue('two');\n controller.enqueue('three');\n controller.close();\n },\n});\n\nasync function* prefixChunks(prefix, asyncIterable) {\n for await (const chunk of asyncIterable) {\n yield '> ' + chunk;\n }\n}\n\nconst transformedAsyncIterable = prefixChunks('> ', stream);\nfor await (const transformedChunk of transformedAsyncIterable) {\n console.log(transformedChunk);\n}\n\n// Output:\n// '> one'\n// '> two'\n// '> three'\n```", "```js\nrs.pipeThrough(ts).pipeTo(ws);\n```", "```js\nrs -pipeTo-> ts{writable,readable} -pipeTo-> ws\n```", "```js\n    const readableByteStream = new ReadableStream({\n     type: 'bytes',\n     async start() { /*...*/ }\n     // ...\n    });\n    ```", "```js\nimport {promisify} from 'node:util';\nimport {randomFill} from 'node:crypto';\nconst asyncRandomFill = promisify(randomFill);\n\nconst readableByteStream = new ReadableStream({\n type: 'bytes',\n async pull(controller) {\n const byobRequest = controller.byobRequest;\n await asyncRandomFill(byobRequest.view);\n byobRequest.respond(byobRequest.view.byteLength);\n },\n});\n\nconst reader = readableByteStream.getReader({mode: 'byob'});\nconst buffer = new Uint8Array(10); // (A)\nconst firstChunk = await reader.read(buffer); // (B)\nconsole.log(firstChunk);\n```", "```js\nconst readableByteStream = new ReadableStream({\n type: 'bytes',\n start(controller) {\n // 256 zeros\n controller.enqueue(new Uint8Array(256));\n controller.close();\n },\n});\nconst transformedStream = readableByteStream.pipeThrough(\n new CompressionStream('gzip'));\nawait logChunks(transformedStream);\n\nasync function logChunks(readableByteStream) {\n const reader = readableByteStream.getReader();\n try {\n while (true) {\n const {done, value} = await reader.read();\n if (done) break;\n console.log(value);\n }\n } finally {\n reader.releaseLock();\n }\n}\n```", "```js\nconst response = await fetch('https://example.com');\nconst readableByteStream = response.body;\nconst readableStream = readableByteStream.pipeThrough(\n new TextDecoderStream('utf-8'));\nfor await (const stringChunk of readableStream) {\n console.log(stringChunk);\n}\n```", "```js\nimport {\n arrayBuffer,\n blob,\n buffer,\n json,\n text,\n} from 'node:stream/consumers';\n```", "```js\nimport * as streamConsumers from 'node:stream/consumers';\n\nconst readableByteStream = new ReadableStream({\n type: 'bytes',\n start(controller) {\n // TextEncoder converts strings to UTF-8 encoded Uint8Arrays\n const encoder = new TextEncoder();\n const view = encoder.encode('\"\ud83d\ude00\"');\n assert.deepEqual(\n view,\n Uint8Array.of(34, 240, 159, 152, 128, 34)\n );\n controller.enqueue(view);\n controller.close();\n },\n});\nconst jsonData = await streamConsumers.json(readableByteStream);\nassert.equal(jsonData, '\ud83d\ude00');\n```", "```js\nimport * as streamConsumers from 'node:stream/consumers';\n\nconst readableByteStream = new ReadableStream({\n start(controller) {\n controller.enqueue('\"\ud83d\ude00\"');\n controller.close();\n },\n});\nconst jsonData = await streamConsumers.json(readableByteStream);\nassert.equal(jsonData, '\ud83d\ude00');\n```"]